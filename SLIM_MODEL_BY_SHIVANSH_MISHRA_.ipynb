{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**SLM MODEL FOR QUESTION ANSWERING**\n",
        "\n"
      ],
      "metadata": {
        "id": "OZ82d6hWquTA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing packages"
      ],
      "metadata": {
        "id": "h3Pp804-s02p"
      }
    },
    {
      "source": [
        "import torch\n",
        "import faiss\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import warnings"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "tCDaTNFrng_J"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppressing Warnings and Downloading NLTK Data"
      ],
      "metadata": {
        "id": "NYL1SSh7tG9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"nltk\")\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"transformers\")\n",
        "\n",
        "nltk.download('punkt', quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n0-r3rpqJqi",
        "outputId": "eeebcc0d-81f4-4bae-a644-7df407ae8111"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a Slim Question-Answering Model"
      ],
      "metadata": {
        "id": "qqiuWye5tcTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SmallLanguageModel:\n",
        "    def __init__(self, book_text):\n",
        "        self.text = book_text\n",
        "        self.sentences = sent_tokenize(self.text)\n",
        "        self.embed_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "        self.sentence_model = SentenceTransformer(self.embed_model)\n",
        "\n",
        "        self.retriever = self._build_index()\n",
        "\n",
        "        self.qa_model = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
        "\n",
        "    def _build_index(self):\n",
        "        sentence_embeddings = self.sentence_model.encode(self.sentences, convert_to_tensor=True)\n",
        "        index = faiss.IndexFlatL2(sentence_embeddings.shape[1])\n",
        "        index.add(sentence_embeddings.cpu().numpy())\n",
        "        return index\n",
        "\n",
        "    def retrieve_context(self, question, top_k=3):\n",
        "        query_embedding = self.sentence_model.encode([question], convert_to_tensor=True)\n",
        "        _, indices = self.retriever.search(query_embedding.cpu().numpy(), top_k)\n",
        "        return \" \".join([self.sentences[i] for i in indices[0]])\n",
        "\n",
        "    def answer_question(self, question):\n",
        "        context = self.retrieve_context(question)\n",
        "        result = self.qa_model(question=question, context=context)\n",
        "        return result[\"answer\"], context"
      ],
      "metadata": {
        "id": "JYj6eewBqN7A"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interactive Q&A with a Small Language Model"
      ],
      "metadata": {
        "id": "OY-X94idto1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "book_path = '/content/Sample.txt'\n",
        "\n",
        "with open(book_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    book_text = f.read()\n",
        "\n",
        "model = SmallLanguageModel(book_text)\n",
        "\n",
        "question = input(\"Enter your question: \")\n",
        "\n",
        "answer, context = model.answer_question(question)\n",
        "\n",
        "print(f\"\\nðŸ“Œ Question: {question}\")\n",
        "print(f\"âœ… Answer: {answer}\")\n",
        "print(f\"ðŸ“– Context: {context}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCMwHLeRqTLo",
        "outputId": "7eaefa03-ad86-4f38-9b47-aca0d4c4901a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your question: Where did Alice ran across ?\n",
            "\n",
            "ðŸ“Œ Question: Where did Alice ran across ?\n",
            "âœ… Answer: the field\n",
            "ðŸ“– Context: There was nothing very remarkable in that; nor did Alice think it so very much out of the way to hear the Rabbit say to itself, 'Oh dear! (when she thought it over afterwards, it occurred to her that she ought to have wondered at this, but at the time it all seemed quite natural); but when the Rabbit actually took a watch out of its waistcoat pocket and looked at it and then hurried on, Alice started to her feet, for it flashed across her mind that she had never before seen a rabbit with either a waistcoat pocket, or a watch to take out of it, and burning with curiosity, she ran across the field after it, and fortunately was just in time to see it pop down a large rabbit-hole under the hedge. Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do: once or twice she had peeped into the book her sister was reading, but it had no pictures or conversations in it, 'and what is the use of a book,' thought Alice 'without pictures or conversation?'\n"
          ]
        }
      ]
    }
  ]
}